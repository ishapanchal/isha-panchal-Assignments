{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('probability of a person playing when the weather is sunny is ', 0.6428571428571429)\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "#What is the probability of a person playing when the weather is sunny? Find P(Yes|Sunny).\n",
    "\n",
    "#Weather     play\n",
    "#           yes  no\n",
    "#sunny      3/9  2/5\n",
    "#overcast   4/9  0/5\n",
    "#rainy      2/9  3/5\n",
    "\n",
    "#p(yes) = 9/14\n",
    "#p(no) = 5/14\n",
    "\n",
    "#p(sunny) = 1/3\n",
    "#p(yes|sunny) = ??\n",
    "\n",
    "from __future__ import division\n",
    "from fractions import Fraction\n",
    "def func1(p_sunny_yes , p_yes , p_sunny):\n",
    "  p_yes_sunny = ((p_sunny_yes * p_yes)/p_sunny)\n",
    "  return p_yes_sunny\n",
    "print('probability of a person playing when the weather is sunny is ' , func1(3/9,9/14,1/3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(' probability of a person playing when the weather is sunny is ', Fraction(16, 25))\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "from fractions import Fraction\n",
    "def func1(p_sunny_yes , p_yes , p_sunny):\n",
    " p_yes_sunny = \"%.2f\"%((p_sunny_yes * p_yes)/p_sunny)\n",
    " print(' probability of a person playing when the weather is sunny is ' , Fraction(p_yes_sunny))\n",
    "func1(3/9,9/14,1/3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 2\n",
    "\n",
    "#Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import classification_report , confusion_matrix , accuracy_score #metrics and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2- a.) ->import iris dataset from sklearn\n",
    "data , target = datasets.load_iris(return_X_y = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150L, 4L)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150L,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(data = target)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2- b.) -> Split the dataset into training and testing sets using train_test_split() \n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train , x_test , y_train , y_test = train_test_split(data , target , test_size = 0.25 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2- c.) -> Use GaussianNB and print the following:\n",
    "#i. Confusion matrix\n",
    "#ii. Classification report\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB , MultinomialNB\n",
    "model1 = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual  Predicted\n",
      "0        1          1\n",
      "1        0          0\n",
      "2        2          2\n",
      "3        1          1\n",
      "4        1          1\n",
      "5        0          0\n",
      "6        1          1\n",
      "7        2          2\n",
      "8        1          1\n",
      "9        1          1\n",
      "10       2          2\n",
      "11       0          0\n",
      "12       0          0\n",
      "13       0          0\n",
      "14       0          0\n",
      "15       1          1\n",
      "16       2          2\n",
      "17       1          1\n",
      "18       1          1\n",
      "19       2          2\n",
      "20       0          0\n",
      "21       2          2\n",
      "22       0          0\n",
      "23       2          2\n",
      "24       2          2\n",
      "25       2          2\n",
      "26       2          2\n",
      "27       2          2\n",
      "28       0          0\n",
      "29       0          0\n",
      "30       0          0\n",
      "31       0          0\n",
      "32       1          1\n",
      "33       0          0\n",
      "34       0          0\n",
      "35       2          2\n",
      "36       1          1\n",
      "37       0          0\n"
     ]
    }
   ],
   "source": [
    "data = {'Actual' : y_test , 'Predicted' : y_pred}\n",
    "output = pd.DataFrame(data = data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  0 12]]\n"
     ]
    }
   ],
   "source": [
    "#c(i) Confusion matrix\n",
    "print(confusion_matrix(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       1.00      1.00      1.00        11\n",
      "          2       1.00      1.00      1.00        12\n",
      "\n",
      "avg / total       1.00      1.00      1.00        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#c(ii) Classification report\n",
    "print(classification_report(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test , y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q.2- d.) -> Use MultinomialNB and print the following:\n",
    "#i. Confusion matrix\n",
    "#ii. Classification report\n",
    "model2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = model2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Actual  Predicted\n",
      "0        1          1\n",
      "1        0          0\n",
      "2        2          2\n",
      "3        1          1\n",
      "4        1          1\n",
      "5        0          0\n",
      "6        1          1\n",
      "7        2          2\n",
      "8        1          1\n",
      "9        1          1\n",
      "10       2          2\n",
      "11       0          0\n",
      "12       0          0\n",
      "13       0          0\n",
      "14       0          0\n",
      "15       1          1\n",
      "16       2          2\n",
      "17       1          1\n",
      "18       1          1\n",
      "19       2          2\n",
      "20       0          0\n",
      "21       2          2\n",
      "22       0          0\n",
      "23       2          2\n",
      "24       2          1\n",
      "25       2          2\n",
      "26       2          2\n",
      "27       2          2\n",
      "28       0          0\n",
      "29       0          0\n",
      "30       0          0\n",
      "31       0          0\n",
      "32       1          1\n",
      "33       0          0\n",
      "34       0          0\n",
      "35       2          2\n",
      "36       1          1\n",
      "37       0          0\n"
     ]
    }
   ],
   "source": [
    "data = {'Actual' : y_test , 'Predicted' : y_pred2}\n",
    "output = pd.DataFrame(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1 11]]\n"
     ]
    }
   ],
   "source": [
    "#d(i) Confusion matrix\n",
    "print(confusion_matrix(y_test , y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        15\n",
      "          1       0.92      1.00      0.96        11\n",
      "          2       1.00      0.92      0.96        12\n",
      "\n",
      "avg / total       0.98      0.97      0.97        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#d(ii) Classification report\n",
    "print(classification_report(y_test , y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test , y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
